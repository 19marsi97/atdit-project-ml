{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E KNN and K-means CIFAR\n",
    "_5 points_\n",
    "\n",
    "transform cifar-10 to grayscale. \n",
    "\n",
    "- Does knn work similarly good?\n",
    "- Does k-means work similarly good?\n",
    "- Demonstrate this similar to  B, C and D <br><br>\n",
    "\n",
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import skimage as ski\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "plt.gray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform to grayscale\n",
    "x_train_bw = ski.color.rgb2gray(x_train)\n",
    "x_test_bw = ski.color.rgb2gray(x_test)\n",
    "\n",
    "# flatten the grayscale dataset\n",
    "x_train_flat = x_train_bw.reshape([x_train.shape[0],\n",
    "                              x_train.shape[1] * x_train.shape[2]])\n",
    "x_test_flat = x_test_bw.reshape([x_test.shape[0],\n",
    "                           x_test.shape[1] * x_test.shape[2]])\n",
    "# flattening the y_arrays\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "x_train_bw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_2 = KNeighborsClassifier(n_neighbors=2, n_jobs=-1)\n",
    "knn_4 = KNeighborsClassifier(n_neighbors=4, n_jobs=-1)\n",
    "knn_8 = KNeighborsClassifier(n_neighbors=8, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=8, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subsampling with 10000 images\n",
    "knn_2.fit(x_train_flat[:10000], y_train[:10000])\n",
    "knn_4.fit(x_train_flat[:10000], y_train[:10000])\n",
    "knn_8.fit(x_train_flat[:10000], y_train[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_2_predictions = knn_2.predict(x_test_flat[:2000])\n",
    "knn_4_predictions = knn_4.predict(x_test_flat[:2000])\n",
    "knn_8_predictions = knn_8.predict(x_test_flat[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for knn 2: 0.798\n",
      "Error rate for knn 4: 0.772\n",
      "Error rate for knn 8: 0.7685\n"
     ]
    }
   ],
   "source": [
    "# As in the previous examples we will use the error rate as 1 - f1_score for all models\n",
    "\n",
    "knn_2_f1_score = f1_score(y_test[:2000], knn_2_predictions, average=\"micro\")\n",
    "knn_4_f1_score = f1_score(y_test[:2000], knn_4_predictions, average=\"micro\")\n",
    "knn_8_f1_score = f1_score(y_test[:2000], knn_8_predictions, average=\"micro\")\n",
    "print(\"Error rate for knn {}: {}\".format(2, (1 - knn_2_f1_score)))\n",
    "print(\"Error rate for knn {}: {}\".format(4, (1 - knn_4_f1_score)))\n",
    "print(\"Error rate for knn {}: {}\".format(8, (1 - knn_8_f1_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rates by model and label\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Knn_2</th>\n",
       "      <th>Knn_4</th>\n",
       "      <th>Knn_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>airplane</th>\n",
       "      <td>0.505102</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.637755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>automobile</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.924242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bird</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.610256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.849246</td>\n",
       "      <td>0.899497</td>\n",
       "      <td>0.909548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deer</th>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.935135</td>\n",
       "      <td>0.935135</td>\n",
       "      <td>0.940541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frog</th>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.800926</td>\n",
       "      <td>0.787037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horse</th>\n",
       "      <td>0.891192</td>\n",
       "      <td>0.875648</td>\n",
       "      <td>0.870466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ship</th>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.460829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truck</th>\n",
       "      <td>0.970443</td>\n",
       "      <td>0.921182</td>\n",
       "      <td>0.901478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Knn_2     Knn_4     Knn_8\n",
       "airplane    0.505102  0.612245  0.637755\n",
       "automobile  0.818182  0.833333  0.924242\n",
       "bird        0.666667  0.646154  0.610256\n",
       "cat         0.849246  0.899497  0.909548\n",
       "deer        0.797980  0.707071  0.676768\n",
       "dog         0.935135  0.935135  0.940541\n",
       "frog        0.907407  0.800926  0.787037\n",
       "horse       0.891192  0.875648  0.870466\n",
       "ship        0.645161  0.516129  0.460829\n",
       "truck       0.970443  0.921182  0.901478"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the individual error rates for each label using the f1_score\n",
    "\n",
    "prediction_array = [knn_2_predictions, knn_4_predictions, knn_8_predictions]\n",
    "results = [] # will later contain the results of all three models\n",
    "for i in range(len(prediction_array)):\n",
    "    predictions = prediction_array[i]\n",
    "    result_array = []\n",
    "    for i in range(10):\n",
    "        indices = np.where(y_test[:2000] ==i)[0]\n",
    "        true_values = y_test[indices] # shorten the y_test array to the specified indices\n",
    "        pred_values = predictions[indices]\n",
    "        result_array.append(1 - f1_score(true_values, pred_values, average=\"micro\"))\n",
    "    results.append(result_array)\n",
    "print(\"Error rates by model and label\")\n",
    "knn_df = pd.DataFrame(np.array(results).T, columns=[\"Knn_2\", \"Knn_4\", \"Knn_8\"], index=class_names)\n",
    "knn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_10_iter = KMeans(n_clusters=10, max_iter=10, n_jobs=-1).fit(x_train_flat[:10000]) # n_jobs = -1 to use all cores for calculation\n",
    "kmeans_100_iter = KMeans(n_clusters=10, max_iter=100, n_jobs=-1).fit(x_train_flat[:10000])\n",
    "kmeans_1000_iter = KMeans(n_clusters=10, max_iter=1000, n_jobs=-1).fit(x_train_flat[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "69\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# visualize how many iterations were actually made\n",
    "print(kmeans_10_iter.n_iter_)\n",
    "print(kmeans_100_iter.n_iter_)\n",
    "print(kmeans_1000_iter.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_10_scores = []\n",
    "kmeans_100_scores = []\n",
    "kmeans_1000_scores = []\n",
    "\n",
    "# create empty multidimensional arrays used for better indexing\n",
    "for i in range(10):\n",
    "    kmeans_10_scores.append([])\n",
    "    kmeans_100_scores.append([])\n",
    "    kmeans_1000_scores.append([])\n",
    "\n",
    "# filling the score_arrays (lists) with the corresponding true labels (y_test)\n",
    "#kmeans_10\n",
    "count = 0\n",
    "for value in kmeans_10_iter.labels_:\n",
    "    kmeans_10_scores[value].append(y_train[count])\n",
    "    count += 1\n",
    "\n",
    "#kmeans_100\n",
    "count = 0\n",
    "for value in kmeans_100_iter.labels_:\n",
    "    kmeans_100_scores[value].append(y_train[count])\n",
    "    count += 1\n",
    "\n",
    "#kmeans_1000\n",
    "count = 0\n",
    "for value in kmeans_1000_iter.labels_:\n",
    "    kmeans_1000_scores[value].append(y_train[count])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate a distribution between the ten classes\n",
    "kmeans_10_clusters = []\n",
    "kmeans_100_clusters = []\n",
    "kmeans_1000_clusters = []\n",
    "for i in range(10):\n",
    "    # 10 iterations\n",
    "    local_array = np.bincount(kmeans_10_scores[:][i])\n",
    "    kmeans_10_clusters.append(local_array)\n",
    "    # 100 iterations\n",
    "    local_array = np.bincount(kmeans_100_scores[:][i])\n",
    "    kmeans_100_clusters.append(local_array)\n",
    "    #1000 iterations\n",
    "    local_array = np.bincount(kmeans_1000_scores[:][i])\n",
    "    kmeans_1000_clusters.append(local_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans with 10 iterations\n",
      "\n",
      "Cluster: 0 => majority label: 4\n",
      "Multiple maximum detected! No value has been added to the result set!\n",
      "Cluster: 2 => majority label: 7\n",
      "Cluster: 3 => majority label: 8\n",
      "Cluster: 4 => majority label: 0\n",
      "Cluster: 5 => majority label: 8\n",
      "Cluster: 6 => majority label: 5\n",
      "Cluster: 7 => majority label: 6\n",
      "Cluster: 8 => majority label: 2\n",
      "Cluster: 9 => majority label: 9\n",
      "The following numbers have no own cluster: [1 3]\n"
     ]
    }
   ],
   "source": [
    "# Calculating the majority label in each cluster and its percentage\n",
    "print(\"Kmeans with 10 iterations\\n\")\n",
    "count = 0\n",
    "labels = np.arange(10)\n",
    "majority_labels_10 = []\n",
    "percentages_maj_cluster_10 = []\n",
    "for array in kmeans_10_clusters:\n",
    "    maximum = np.where(array == max(array))[0]\n",
    "    if len(maximum) == 1:\n",
    "        print(\"Cluster: {} => majority label: {}\".format(count, maximum[0]))    \n",
    "        majority_labels_10.append(maximum[0])\n",
    "        percentages_maj_cluster_10.append(max(array) / sum(array))\n",
    "    else: # catch the case that the maximum exists more than once in a cluster\n",
    "        print(\"Multiple maximum detected! No value has been added to the result set!\")\n",
    "    count += 1\n",
    "differences_10_iter = np.where(np.isin(labels, majority_labels_10) == False)[0]\n",
    "print(\"The following numbers have no own cluster: {}\".format(differences_10_iter))\n",
    "#print(percentages_maj_cluster_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans with 100 iterations\n",
      "\n",
      "Cluster: 0 => majority label: 9\n",
      "Cluster: 1 => majority label: 0\n",
      "Cluster: 2 => majority label: 2\n",
      "Cluster: 3 => majority label: 4\n",
      "Cluster: 4 => majority label: 7\n",
      "Cluster: 5 => majority label: 9\n",
      "Cluster: 6 => majority label: 8\n",
      "Cluster: 7 => majority label: 6\n",
      "Cluster: 8 => majority label: 8\n",
      "Cluster: 9 => majority label: 6\n",
      "The following numbers have no own cluster: [1 3 5]\n"
     ]
    }
   ],
   "source": [
    "print(\"Kmeans with 100 iterations\\n\")\n",
    "count = 0\n",
    "labels = np.arange(10)\n",
    "majority_labels_100 = []\n",
    "percentages_maj_cluster_100 = []\n",
    "for array in kmeans_100_clusters:\n",
    "    maximum = np.where(array == max(array))[0]\n",
    "    if len(maximum) == 1:\n",
    "        print(\"Cluster: {} => majority label: {}\".format(count, maximum[0]))    \n",
    "        majority_labels_100.append(maximum[0])\n",
    "        percentages_maj_cluster_100.append(max(array) / sum(array))\n",
    "    else:\n",
    "        print(\"Multiple maximum detected! No value has been added to the result set!\")\n",
    "    count += 1\n",
    "differences_100_iter = np.where(np.isin(labels, majority_labels_100) == False)[0]\n",
    "print(\"The following numbers have no own cluster: {}\".format(differences_100_iter))\n",
    "#print(percentages_maj_cluster_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans with 1000 iterations\n",
      "\n",
      "Cluster: 0 => majority label: 9\n",
      "Cluster: 1 => majority label: 8\n",
      "Cluster: 2 => majority label: 9\n",
      "Cluster: 3 => majority label: 4\n",
      "Cluster: 4 => majority label: 2\n",
      "Cluster: 5 => majority label: 6\n",
      "Cluster: 6 => majority label: 7\n",
      "Cluster: 7 => majority label: 0\n",
      "Cluster: 8 => majority label: 6\n",
      "Cluster: 9 => majority label: 8\n",
      "The following numbers have no own cluster: [1 3 5]\n"
     ]
    }
   ],
   "source": [
    "print(\"Kmeans with 1000 iterations\\n\")\n",
    "count = 0\n",
    "labels = np.arange(10)\n",
    "majority_labels_1000 = []\n",
    "percentages_maj_cluster_1000 = []\n",
    "for array in kmeans_1000_clusters:\n",
    "    maximum = np.where(array == max(array))[0]\n",
    "    if len(maximum) == 1:\n",
    "        print(\"Cluster: {} => majority label: {}\".format(count, maximum[0]))    \n",
    "        majority_labels_1000.append(maximum[0])\n",
    "        percentages_maj_cluster_1000.append(max(array) / sum(array))\n",
    "    else:\n",
    "        print(\"Multiple maximum detected! No value has been added to the result set!\")\n",
    "    count += 1\n",
    "differences_1000_iter = np.where(np.isin(labels, majority_labels_1000) == False)[0]\n",
    "print(\"The following numbers have no own cluster: {}\".format(differences_1000_iter))\n",
    "#print(percentages_maj_cluster_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.209402</td>\n",
       "      <td>0.301136</td>\n",
       "      <td>0.305825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.165523</td>\n",
       "      <td>0.333895</td>\n",
       "      <td>0.150897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.280130</td>\n",
       "      <td>0.164662</td>\n",
       "      <td>0.188047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.329966</td>\n",
       "      <td>0.191985</td>\n",
       "      <td>0.203636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.256219</td>\n",
       "      <td>0.158046</td>\n",
       "      <td>0.163601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.206831</td>\n",
       "      <td>0.182561</td>\n",
       "      <td>0.150168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.216524</td>\n",
       "      <td>0.314249</td>\n",
       "      <td>0.142271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.332186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.351634</td>\n",
       "      <td>0.152876</td>\n",
       "      <td>0.228321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.227216</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  0.209402  0.301136  0.305825\n",
       "1  0.165523  0.333895  0.150897\n",
       "2  0.280130  0.164662  0.188047\n",
       "3  0.329966  0.191985  0.203636\n",
       "4  0.256219  0.158046  0.163601\n",
       "5  0.206831  0.182561  0.150168\n",
       "6  0.216524  0.314249  0.142271\n",
       "7  0.181818  0.155556  0.332186\n",
       "8  0.351634  0.152876  0.228321\n",
       "9       NaN  0.227216  0.315789"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_percentages = [percentages_maj_cluster_10, percentages_maj_cluster_100, percentages_maj_cluster_1000]\n",
    "df0 = pd.DataFrame(combined_percentages)#, columns=[\"10\", \"100\", \"1000\"])\n",
    "df0.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task D: What is difficult to predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new knn model\n",
    "knn_3 = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "knn_3.fit(x_train_flat[:10000], y_train[:10000])\n",
    "knn_3_predictions = knn_3.predict(x_test_flat[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score of the knn model\n",
    "print(f1_score(y_test[:2000], predictions[:2000], average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# error contains all indices where the predictions do not match the real labels\n",
    "error = []\n",
    "count = 0\n",
    "for value in knn_3_predictions:\n",
    "    if value != y_test[count]:\n",
    "        error.append(count)\n",
    "    count += 1\n",
    "#error = np.where(knn_3_predictions == y_test)\n",
    "print(knn_3_predictions[:20])\n",
    "print(y_test[:20])\n",
    "#print(error)\n",
    "# looking at example images that were not identified correctly\n",
    "for value in error[:25]:\n",
    "    x_val = value\n",
    "    print(\"Prediction: {}\".format(class_names[knn_3.predict([x_test_bw[x_val].reshape(32*32)])[0]]))\n",
    "    print(\"Real value: {}\".format(class_names[y_test[x_val]]))\n",
    "    plt.imshow(x_test_bw[x_val])\n",
    "    plt.show()\n",
    "    \n",
    "#print(\"Knn Labels not recognized: {}\".format(np.bincount(y_test[error])))\n",
    "#print(\"Knn Labels wrongly classified: {}\".format(np.bincount(predictions[error])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"What is shown in these pictures?\")\n",
    "arr = [6, 17, 21]\n",
    "strings = [\"cat\", \"deer\", \"deer\"]\n",
    "for i in arr:\n",
    "    print(\"Real value: {}\".format(strings.pop(0)))\n",
    "    plt.imshow(x_test_bw[error[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer\n",
    "\n",
    "## Evaluating similarities on knn and kmeans compared to the MNIST dataset\n",
    "\n",
    "In comparison to the MNIST dataset, the CIPHER10 dataset has very bad results. While the error rate for all three Knns on the MNIST dataset was around 3%, the CIPHER10 dataset has errors around 76-79%.<br>\n",
    "Also the kmeans model did not perform better because more categories have no own cluster and the individual percentages in the clusters decreased, meaning the predicted values inside a cluster are close next to each other leading to many false predicitons.<br>\n",
    "At this point we have to say that the CIPHER10 dataset was only used as a subsample because of runtime issues (10k training, 2k test). The results might differ if the whole dataset is used.\n",
    "\n",
    "## Ex. B for CIPHER10\n",
    "\n",
    "The CIPHER10 has the following error rates for the different knn models:<br>\n",
    "Error rate for knn 2: 0.798<br>\n",
    "Error rate for knn 4: 0.772<br>\n",
    "Error rate for knn 8: 0.7685<br>\n",
    "\n",
    "The individual error rates can be seen below. There, one can see that especially the most classes perform very bad, so we want to highlight the ones that were not completely false. For knn = 2 the class airplane performed best with around 50% false predictions; for knn = 4 the class ship was around 50% failure and for knn = 8 the class ship has below 50% failure.<br>\n",
    "All other classes have higher error rates, going up to 97% (knn = 2 class: truck).\n",
    "\n",
    "In contrast to the MNIST dataset, one can see a solid difference by changing the value for k. Firstly, with a rising k (in our example from 2 to 4 to 8) the overall error rate decreases; nevertheless it is a very horrible score.\n",
    "Furthermore, with a rising k the errors in some classes constantly increase or decrease; for example increasing errors for rising k in classes \"cat\" and \"dog\" and decreasing errors for rising k in \"bird\", \"deer\" and \"ship\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. C for CIPHER10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority classes for each cluster:<br>\n",
    "<b>For max_iterations = 10</b><br>\n",
    "Cluster: 0 => majority label: 9\n",
    "Cluster: 1 => majority label: 5\n",
    "Cluster: 2 => majority label: 8\n",
    "Cluster: 3 => majority label: 2\n",
    "Cluster: 4 => majority label: 6\n",
    "Cluster: 5 => majority label: 6\n",
    "Cluster: 6 => majority label: 8\n",
    "Cluster: 7 => majority label: 7\n",
    "Cluster: 8 => majority label: 0\n",
    "Cluster: 9 => majority label: 4<br><br>\n",
    "\n",
    "Majority classes for each cluster:<br>\n",
    "<b>For max_iterations = 100</b><br>\n",
    "Cluster: 0 => majority label: 7\n",
    "Cluster: 1 => majority label: 9\n",
    "Cluster: 2 => majority label: 8\n",
    "Cluster: 3 => majority label: 2\n",
    "Cluster: 4 => majority label: 9\n",
    "Cluster: 5 => majority label: 6\n",
    "Cluster: 6 => majority label: 6\n",
    "Cluster: 7 => majority label: 4\n",
    "Cluster: 8 => majority label: 0\n",
    "Cluster: 9 => majority label: 8<br><br>\n",
    "\n",
    "Majority classes for each cluster:<br>\n",
    "<b>For max_iterations = 1000</b><br>\n",
    "Cluster: 0 => majority label: 7\n",
    "Cluster: 1 => majority label: 6\n",
    "Cluster: 2 => majority label: 8\n",
    "Cluster: 3 => majority label: 2\n",
    "Cluster: 4 => majority label: 8\n",
    "Cluster: 5 => majority label: 9\n",
    "Cluster: 6 => majority label: 0\n",
    "Cluster: 7 => majority label: 4\n",
    "Cluster: 8 => majority label: 6\n",
    "Cluster: 9 => majority label: 9<br><br>\n",
    "\n",
    "<b>Categories that have no own cluster:</b><br>\n",
    "max_iter=10: Classes 1 and 3<br>\n",
    "max_iter=100: Classes 1, 3 and 5<br>\n",
    "max_iter=1000: Classes 1, 3 and 5<br><br>\n",
    "\n",
    "### Majority percentage in the cluster (table below)\n",
    "One can see that the classes in many clusters have to be very even distributed, if the maximum class only reaches percentages around 13-19%. On the other hand, in some classes the maximum category is far stronger (>30%); however, compared to the MNIST dataset where the maximum categories reached up to 90% and never fell below 35% this values are a good proof that the Kmeans model is not very effective for this task/dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. D for CIPHER10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, one can say that no class is predicted with a good accuracy. But, as seen above at the images, some classes are worse to predict than others. Problems occur especially with the animal classes, for example dogs and cats are often not recognized and mislabeled. <br>\n",
    "The performance for trucks and especially ships on the other hand are far better; however, regarding the absolute values and comparing it to the MNIST dataset the errors are still very high.<br>\n",
    "Finally, we can say that this dataset is harder to predict than the MNIST dataset. This might be because the classes are more complicated; the pictures are a little bigger and transforming the images to grayscale might take important features out of the pictures which could be recognized in another model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
