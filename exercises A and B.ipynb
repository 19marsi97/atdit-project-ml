{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# A KNN\n",
    "_2 points_\n",
    "\n",
    "- How many distances you need to calculate if you have 60,000 samples in the trainingset for 50 samples? \n",
    "- How many distances do you need to calculate if you have n samples im the trainingset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "A 1. 60000 samples (training). <br>\n",
    "50 samples are tested on the set, finding the closest to the given sample. <br>\n",
    "For each sample, all pictures are checked, so per sample 60000 distances are calculated. <br>\n",
    "So, this follows into: 60000 \\* 50 = 3.000.000 distances total <br><br>\n",
    "A 2. Examples trainingset (n) \\* Samples = total distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B KNN MNIST\n",
    "_3 points_\n",
    "\n",
    "- What is the error rate of KNN on the test set?\n",
    "- What is the error rate for each label (number)?\n",
    "\n",
    "Do for k = 2, 4, 8\n",
    "\n",
    "- How does the choice of k influence the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() # load dataset\n",
    "# reshape the train sets into 2D arrays\n",
    "x_train_flat = x_train.reshape([x_train.shape[0],\n",
    "                              x_train.shape[1] * x_train.shape[2]])\n",
    "x_test_flat = x_test.reshape([x_test.shape[0],\n",
    "                           x_test.shape[1] * x_test.shape[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the KNN models with k = 2, 4, 8\n",
    "# n_jobs = -1 makes sure that all cores are used for the model\n",
    "knn_2 = KNeighborsClassifier(n_neighbors=2, n_jobs=-1)\n",
    "knn_4 = KNeighborsClassifier(n_neighbors=4, n_jobs=-1)\n",
    "knn_8 = KNeighborsClassifier(n_neighbors=8, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=8, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the train set into the knn models\n",
    "knn_2.fit(x_train_flat, y_train)\n",
    "knn_4.fit(x_train_flat, y_train)\n",
    "knn_8.fit(x_train_flat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_2_predictions = knn_2.predict(x_test_flat)\n",
    "knn_4_predictions = knn_4.predict(x_test_flat)\n",
    "knn_8_predictions = knn_8.predict(x_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for knn 2: 0.0373\n",
      "Error rate for knn 4: 0.03180000000000005\n",
      "Error rate for knn 8: 0.03300000000000003\n"
     ]
    }
   ],
   "source": [
    "# Assumption: We define the error rate as 1 - f1 score.\n",
    "# We chose the f1 score because it combines the results from the precision and recall results.\n",
    "# Because we have a multiclass model we chose \"micro\" as the average parameter to get a global overview of the score.\n",
    "knn_2_f1_score = f1_score(y_test, knn_2_predictions, average=\"micro\")\n",
    "knn_4_f1_score = f1_score(y_test, knn_4_predictions, average=\"micro\")\n",
    "knn_8_f1_score = f1_score(y_test, knn_8_predictions, average=\"micro\")\n",
    "print(\"Error rate for knn {}: {}\".format(2, (1 - knn_2_f1_score)))\n",
    "print(\"Error rate for knn {}: {}\".format(4, (1 - knn_4_f1_score)))\n",
    "print(\"Error rate for knn {}: {}\".format(8, (1 - knn_8_f1_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rates by model and label\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Knn_2</th>\n",
       "      <th>Knn_4</th>\n",
       "      <th>Knn_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004082</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>0.007143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.002643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.037791</td>\n",
       "      <td>0.050388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028713</td>\n",
       "      <td>0.030693</td>\n",
       "      <td>0.033663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023422</td>\n",
       "      <td>0.030550</td>\n",
       "      <td>0.039715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.047085</td>\n",
       "      <td>0.033632</td>\n",
       "      <td>0.026906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.019833</td>\n",
       "      <td>0.016701</td>\n",
       "      <td>0.015658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.045720</td>\n",
       "      <td>0.038911</td>\n",
       "      <td>0.041829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.100616</td>\n",
       "      <td>0.073922</td>\n",
       "      <td>0.065708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.071358</td>\n",
       "      <td>0.053518</td>\n",
       "      <td>0.048563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Knn_2     Knn_4     Knn_8\n",
       "0  0.004082  0.004082  0.007143\n",
       "1  0.001762  0.001762  0.002643\n",
       "2  0.035853  0.037791  0.050388\n",
       "3  0.028713  0.030693  0.033663\n",
       "4  0.023422  0.030550  0.039715\n",
       "5  0.047085  0.033632  0.026906\n",
       "6  0.019833  0.016701  0.015658\n",
       "7  0.045720  0.038911  0.041829\n",
       "8  0.100616  0.073922  0.065708\n",
       "9  0.071358  0.053518  0.048563"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "To calculate the individual error rates, we will isolate the prediction results\n",
    "by individual labels and define the error rate again as 1 - f1 score\n",
    "This will be applied to all knn models through the outer loop\n",
    "The results will be stored in the \"results\" array with the following structure: the first dimension\n",
    "defines the knn model in order 2, 4, 8; the second dimension defines the label (0-9)\n",
    "\"\"\"\n",
    "\n",
    "prediction_array = [knn_2_predictions, knn_4_predictions, knn_8_predictions]\n",
    "results = []\n",
    "for i in range(len(prediction_array)):\n",
    "    predictions = prediction_array[i]\n",
    "    result_array = []\n",
    "    for i in range(10):\n",
    "        indices = np.where(y_test ==i)\n",
    "        indices = indices[0] # np. where returns a tuple with the first element being the array we want to work with\n",
    "        #print(\"{}: {}\".format(i, indices.shape))\n",
    "        true_values = y_test[indices] # similar to an array with (len(indices))-times the number i\n",
    "        #print(true_values)\n",
    "        pred_values = predictions[indices]\n",
    "        #print(pred_values)\n",
    "        result_array.append(1 - f1_score(true_values, pred_values, average=\"micro\"))\n",
    "        #print(f1_score(true_values, pred_values, average=\"micro\"))\n",
    "    results.append(result_array)\n",
    "    #print(result_array)\n",
    "print(\"Error rates by model and label\")\n",
    "pd.DataFrame(np.array(results).T, columns=[\"Knn_2\", \"Knn_4\", \"Knn_8\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "In this exercise and all following examples, we chose the f1 score because it combines the results from the precision and recall results. Because we have a multiclass models we chose \"micro\" as the average parameter to get a global overview of the score.\n",
    "\n",
    "\n",
    "The error rates (in our scenario defined as 1 - f1 score) do not differ that much between the three models.<br>\n",
    "For knn = 2 the error rate is: 0.0373<br>\n",
    "For knn = 4 the error rate is: 0.03180000000000005<br>\n",
    "For knn = 8 the error rate is: 0.03300000000000003<br>\n",
    "\n",
    "The individual error rates can be seen in the Dataframe above.<br><br>\n",
    "\n",
    "<b>Changing the value of k</b> does not have a big impact on the overall error rate; however, the individual error rates change a lot especially when comparing Knn_2 and Knn_8.<br>\n",
    "For example, Knn_2 has an error rate of .0041 at the label \"0\" while Knn_8 has an error rate of .0071\n",
    "This effect can also be seen at labels 1, 2, 5, 8, 9\n",
    "\n",
    "In addidition, we question the usage of even parameters for k in the model generation because a collision between categories is possible, and maybe very common with k = 2 if both labels of the neighbors do not match. Maybe one can receive a higher accuracy using an uneven number like k = 3. (we tested this in the cell below and calculated an f1_score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNeighborsClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fd6f89d1cb5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mknn_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_flat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mknn_3_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_flat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mknn_3_f1_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_3_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"micro\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error rate for knn 3: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mknn_2_f1_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The error rates for knn2, knn4 and knn8 were: 0.0373; 0.0318; 0.0330\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KNeighborsClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "knn_3 = KNeighborsClassifier(n_neighbors=3, n_jobs=-1).fit(x_train_flat, y_train)\n",
    "knn_3_predictions = knn_3.predict(x_test_flat)\n",
    "knn_3_f1_score = f1_score(y_test, knn_3_predictions, average=\"micro\")\n",
    "print(\"Error rate for knn 3: {}\".format(1 - knn_2_f1_score))\n",
    "print(\"The error rates for knn2, knn4 and knn8 were: 0.0373; 0.0318; 0.0330\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
