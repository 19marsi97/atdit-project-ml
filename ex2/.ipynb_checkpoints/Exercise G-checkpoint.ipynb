{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G Neural Networks Overfitting\n",
    "_6 points_\n",
    "\n",
    "- Train a neural net and prevent overfitting by regularization. \n",
    "- You can use any combination of regularizers we saw in class.\n",
    "- Use the train and test splits in the data do evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Activation\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change batch_size and epochs for fine tuning\n",
    "# image_classes MUST remain at 10!!!\n",
    "\n",
    "batch_size = 64\n",
    "image_classes = 10\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = to_categorical(y_train, image_classes)\n",
    "y_test = to_categorical(y_test, image_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used some different model configurations to create a fitting model\n",
    "# for the cifar dataset\n",
    "model = Sequential()\n",
    "decay = 1e-4\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), activation=\"hard_sigmoid\", input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(decay)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"hard_sigmoid\", input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(decay)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation=\"hard_sigmoid\", kernel_regularizer=regularizers.l2(decay)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), activation=\"hard_sigmoid\", kernel_regularizer=regularizers.l2(decay)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation=\"hard_sigmoid\", input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation=\"hard_sigmoid\", input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(128, activation='hard_sigmoid'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(image_classes, activation=\"hard_sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilation\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 5000\n",
    "test_size = 8000\n",
    "if (y_test.shape == (10000, 10)):\n",
    "    model.fit(x_train[:train_size], y_train[:train_size],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          shuffle=True,\n",
    "          validation_data=(x_test[:test_size], y_test[:test_size]))\n",
    "else:\n",
    "    raise AttributeError(\"y_test.shape must be (10000, 10) but is {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test[test_size:], y_test[test_size:], verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
