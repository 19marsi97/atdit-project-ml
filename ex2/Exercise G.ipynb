{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G Neural Networks Overfitting\n",
    "_6 points_\n",
    "\n",
    "- Train a neural net and prevent overfitting by regularization. \n",
    "- You can use any combination of regularizers we saw in class.\n",
    "- Use the train and test splits in the data do evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Activation\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change batch_size and epochs for fine tuning\n",
    "# image_classes MUST remain at 10!!!\n",
    "\n",
    "batch_size = 64\n",
    "image_classes = 10\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = to_categorical(y_train, image_classes)\n",
    "y_test = to_categorical(y_test, image_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\d070700\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1062: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# We used some different model configurations to create a fitting model\n",
    "# for the cifar dataset\n",
    "model = Sequential()\n",
    "decay = 1e-4\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), activation=\"hard_sigmoid\", input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(decay)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"hard_sigmoid\", input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(decay)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation=\"hard_sigmoid\", kernel_regularizer=regularizers.l2(decay)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), activation=\"hard_sigmoid\", kernel_regularizer=regularizers.l2(decay)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation=\"hard_sigmoid\", input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(decay)))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Conv2D(128, kernel_size=(3, 3), activation=\"hard_sigmoid\", input_shape=(32, 32, 3), kernel_regularizer=regularizers.l2(decay)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(128, activation='hard_sigmoid'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(image_classes, activation=\"hard_sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\d070700\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1123: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 28, 28, 32)        2432      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 11, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 2, 2, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 143,530.0\n",
      "Trainable params: 142,890.0\n",
      "Non-trainable params: 640.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compilation\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 50000\n",
    "test_size = 8000\n",
    "if (y_test.shape == (10000, 10)):\n",
    "    model.fit(x_train[:train_size], y_train[:train_size],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          shuffle=True,\n",
    "          validation_data=(x_test[:test_size], y_test[:test_size]))\n",
    "else:\n",
    "    raise AttributeError(\"y_test.shape must be (10000, 10) but is {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test[test_size:], y_test[test_size:], verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
